{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde74a5d",
   "metadata": {},
   "source": [
    "## Import Datasets\n",
    "\n",
    "**Make sure that you've downloaded the required human and dog datasets:\n",
    "Download the dog dataset. Unzip the folder and place it in this project's home directory, at the location /dog_images.\n",
    "Download the human dataset. Unzip the folder and place it in the home directory, at location /lfw.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip dogImages.zip\n",
    "#!unzip lfw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"./lfw/*/*\"))\n",
    "dog_files = np.array(glob(\"./dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(dog_files[1])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9150fd",
   "metadata": {},
   "source": [
    "## Obtain Pre-trained VGG-16 Model\n",
    "**The code cell below downloads the VGG-16 model, along with weights that have been trained on ImageNet, a very large, very popular dataset used for image classification and other vision tasks. ImageNet contains over 10 million URLs, each linking to an image containing an object from one of 1000 categories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea714d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99212af1",
   "metadata": {},
   "source": [
    "First, we can use the load_img() function to load the image and resize it to the required size of 224Ã—224 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "image = load_img('./dogImages/train/001.Affenpinscher/Affenpinscher_00002.jpg',target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b621edb",
   "metadata": {},
   "source": [
    "Next, we can convert the pixels to a NumPy array so that we can work with it in Keras. We can use the img_to_array() function for this. We only have one sample (one image). We can reshape the array by calling reshape() and adding the extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767281a",
   "metadata": {},
   "source": [
    "Keras provides a function called preprocess_input() to prepare new input for the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e843803",
   "metadata": {},
   "source": [
    "We are now ready to make a prediction for our loaded and prepared image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(image)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46507afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "label = decode_predictions(yhat)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label[0][0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320beb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b8aac",
   "metadata": {},
   "source": [
    "# Complite solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de507b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# load an image from file\n",
    "image = load_img('./dogImages/train/001.Affenpinscher/Affenpinscher_00002.jpg',target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde3e95",
   "metadata": {},
   "source": [
    "# Now we do transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42490fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = '/content/drive/My Drive/Colab Notebooks/dogImages'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "validation_dir = os.path.join(base_dir, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25947279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "training_set = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(150, 150))\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=32,\n",
    "                                                  image_size=(150, 150))\n",
    "\n",
    "val_dataset = image_dataset_from_directory(validation_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=32,\n",
    "                                                  image_size=(150, 150))\n",
    "\n",
    "# Detailed setting about lables_mode and etc ... can be found in the following link\n",
    "# https://docs.w3cub.com/tensorflow~2.3/keras/preprocessing/image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [       keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "   keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eed1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d0521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
